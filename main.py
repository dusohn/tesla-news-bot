import os
import sys
import re
import json
import time
import datetime
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import quote

import requests
import pytz
from bs4 import BeautifulSoup

# -------------------------------
# Environment Variables
# -------------------------------
OPENAI_API_KEY = (os.environ.get("OPENAI_API_KEY") or "").strip()
TELEGRAM_TOKEN = (os.environ.get("TELEGRAM_TOKEN") or "").strip()
CHAT_ID = (os.environ.get("CHAT_ID") or "").strip()

OPENAI_MODEL = (os.environ.get("OPENAI_MODEL") or "gpt-4o-mini").strip()
OPENAI_URL = "https://api.openai.com/v1/responses"

# Telegram message hard limit is 4096
TELEGRAM_CHUNK_SIZE = 3800

# Finviz anti-bot softening
FINVIZ_SLEEP_SEC = 1.0

MAG7 = [
    {"name": "Apple", "ticker": "AAPL", "emoji": "ğŸ"},
    {"name": "Microsoft", "ticker": "MSFT", "emoji": "ğŸ’»"},
    {"name": "Amazon", "ticker": "AMZN", "emoji": "ğŸ“¦"},
    {"name": "Alphabet", "ticker": "GOOGL", "emoji": "ğŸ”"},
    {"name": "Meta", "ticker": "META", "emoji": "ğŸ§ "},
    {"name": "NVIDIA", "ticker": "NVDA", "emoji": "ğŸ¤–"},
    {"name": "Tesla", "ticker": "TSLA", "emoji": "ğŸš—"},
]


EARNINGS_KEYWORDS = [
    # ì‹¤ì /ë°œí‘œ/ê°€ì´ë˜ìŠ¤/ì»¨í¼ëŸ°ìŠ¤ì½œ
    "earnings", "results", "reports", "reported", "q1", "q2", "q3", "q4",
    "quarter", "fiscal", "fy", "guidance", "outlook", "forecast",
    "eps", "revenue", "sales", "profit", "margin",
    "beat", "miss", "tops", "falls short",
    "conference call", "call transcript",
    "preliminary results", "financial results",
    "estimates", "consensus",
]

def is_earnings_headline(title: str) -> bool:
    t = (title or "").lower()
    return any(k in t for k in EARNINGS_KEYWORDS)

def filter_earnings_only_if_earnings_day(items: List[Dict[str, str]]) -> Tuple[List[Dict[str, str]], bool]:
    """
    ìµœê·¼ 24ì‹œê°„ ëª©ë¡ì— 'ì‹¤ì /earnings' ì‹œê·¸ë„ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´
    í•´ë‹¹ í‹°ì»¤ëŠ” 'ì‹¤ì  ê´€ë ¨ ê¸°ì‚¬ë§Œ' ë‚¨ê¸´ë‹¤.
    ë°˜í™˜: (filtered_items, earnings_mode_enabled)
    """
    if not items:
        return items, False

    has_earnings = any(is_earnings_headline(it.get("title", "")) for it in items)
    if not has_earnings:
        return items, False

    filtered = [it for it in items if is_earnings_headline(it.get("title", ""))]
    # ë§Œì•½ ë„ˆë¬´ ë¹¡ì„¸ê²Œ ê±¸ëŸ¬ì„œ 0ê°œê°€ ë˜ë©´ ì›ë³¸ ìœ ì§€(ì•ˆì „ì¥ì¹˜)
    if not filtered:
        return items, False

    return filtered, True

# -------------------------------
# OpenAI Responses API helpers
# -------------------------------
def _extract_output_text(res_json: dict) -> str:
    """
    Responses API ì‘ë‹µì—ì„œ output_textë§Œ í•©ì³ ì¶”ì¶œ
    """
    text_parts = []
    for item in (res_json.get("output") or []):
        for c in (item.get("content") or []):
            if c.get("type") == "output_text" and isinstance(c.get("text"), str):
                text_parts.append(c["text"])
    return "\n".join(t.strip() for t in text_parts if t and t.strip()).strip()


# -------------------------------
# Finviz time parsing (ET -> KST filtering)
# -------------------------------
def _parse_finviz_dt_et(raw: str, now_et: datetime.datetime, last_date_et: Optional[datetime.date]) -> Optional[datetime.datetime]:
    """
    Finviz ë‰´ìŠ¤ í…Œì´ë¸”ì˜ ì‹œê°„ ë¬¸ìì—´ì„ US/Eastern aware datetimeìœ¼ë¡œ íŒŒì‹±.
    ì§€ì› ì˜ˆ:
      - "Feb-03-26 08:35AM"
      - "Today 08:35AM"
      - "08:12AM" (ì´ ê²½ìš° last_date_et í•„ìš”)
    """
    et = pytz.timezone("US/Eastern")
    s = (raw or "").strip()
    if not s:
        return None

    # Today 08:35AM
    if s.lower().startswith("today"):
        parts = s.split()
        if len(parts) >= 2:
            tstr = parts[-1]
            try:
                t = datetime.datetime.strptime(tstr, "%I:%M%p").time()
                return et.localize(datetime.datetime(now_et.year, now_et.month, now_et.day, t.hour, t.minute))
            except Exception:
                return None
        return None

    # "Feb-03-26 08:35AM"
    try:
        dt = datetime.datetime.strptime(s, "%b-%d-%y %I:%M%p")
        return et.localize(dt)
    except Exception:
        pass

    # "08:12AM" (time only)
    try:
        t = datetime.datetime.strptime(s, "%I:%M%p").time()
        if last_date_et is None:
            return None
        return et.localize(datetime.datetime(last_date_et.year, last_date_et.month, last_date_et.day, t.hour, t.minute))
    except Exception:
        return None


def _norm_title(s: str) -> str:
    """
    ì¤‘ë³µ ê¸°ì‚¬ ë³‘í•©ìš© íƒ€ì´í‹€ ì •ê·œí™”
    """
    s = (s or "").strip().lower()
    s = re.sub(r"\s+", " ", s)
    s = re.sub(r"[â€™â€˜Â´`]", "'", s)
    s = re.sub(r"[^a-z0-9ê°€-í£\s'\-:,.!?()/%&]", "", s)
    return s


def fetch_finviz_news_with_links_24h(ticker: str, max_items: int = 120) -> List[Dict[str, str]]:
    """
    Finviz quote í˜ì´ì§€ ë‰´ìŠ¤ í…Œì´ë¸”ì—ì„œ title/url/publishedë¥¼ ìˆ˜ì§‘í•˜ê³ ,
    ìµœê·¼ 24ì‹œê°„(KST ê¸°ì¤€)ë§Œ ë‚¨ê¸´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.
    """
    url = f"https://finviz.com/quote.ashx?t={quote(ticker)}"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
        )
    }

    r = requests.get(url, headers=headers, timeout=20)
    r.raise_for_status()

    soup = BeautifulSoup(r.text, "lxml")
    table = soup.find("table", class_="news-table")
    if not table:
        return []

    kst = pytz.timezone("Asia/Seoul")
    et = pytz.timezone("US/Eastern")

    now_kst = datetime.datetime.now(kst)
    now_et = now_kst.astimezone(et)
    cutoff_kst = now_kst - datetime.timedelta(hours=24)

    items: List[Dict[str, str]] = []
    last_date_et: Optional[datetime.date] = None

    for row in table.find_all("tr"):
        tds = row.find_all("td")
        if len(tds) < 2:
            continue

        raw_dt = tds[0].get_text(" ", strip=True)  # "Feb-03-26 08:35AM" or "08:12AM"
        a = tds[1].find("a")
        title = a.get_text(" ", strip=True) if a else tds[1].get_text(" ", strip=True)
        link = (a.get("href", "").strip() if a else "")

        if not title:
            continue

        dt_et = _parse_finviz_dt_et(raw_dt, now_et, last_date_et)
        if dt_et is None:
            continue

        last_date_et = dt_et.date()
        dt_kst = dt_et.astimezone(kst)

        if dt_kst < cutoff_kst:
            continue

        items.append(
            {
                "title": title,
                "url": link,
                "published": raw_dt,
                "published_kst": dt_kst.isoformat(),
            }
        )

        if len(items) >= max_items:
            break

    return items

def fetch_finviz_price_change(ticker: str) -> Tuple[str, str]:
    """
    Finviz quote í˜ì´ì§€ì—ì„œ Price / Change(%)ë¥¼ íŒŒì‹±.
    ë°˜í™˜: (price_str, change_str). ì‹¤íŒ¨ ì‹œ ("", "")
    """
    url = f"https://finviz.com/quote.ashx?t={quote(ticker)}"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
        )
    }

    try:
        r = requests.get(url, headers=headers, timeout=20)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "lxml")

        table = soup.find("table", class_="snapshot-table2")
        if not table:
            return "", ""

        tds = [td.get_text(" ", strip=True) for td in table.find_all("td")]
        # snapshot-table2ëŠ” ë³´í†µ [Label, Value, Label, Value, ...] í˜•íƒœ
        fields = {}
        for i in range(0, len(tds) - 1, 2):
            label = tds[i]
            value = tds[i + 1]
            if label and value:
                fields[label] = value

        price = (fields.get("Price") or "").strip()
        change = (fields.get("Change") or "").strip()

        # Changeê°€ "+1.23%" í˜•íƒœë¡œ ì˜¤ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return price, change

    except Exception:
        return "", ""


def dedupe_news(items: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    ì œëª© ê¸°ë°˜ ì¤‘ë³µ ë³‘í•©
    """
    out: List[Dict[str, str]] = []
    seen = set()
    for it in items:
        key = _norm_title(it.get("title", ""))
        if not key or key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out


# -------------------------------
# Summarization: 10 lines (+ TSLA 20) from Finviz headlines only
# -------------------------------
def summarize_ticker_lines_from_headlines(
    ticker: str,
    company_name: str,
    news_items: List[Dict[str, str]],
    n_lines: int,
    max_headlines_for_llm: int = 12,
) -> str:
    """
    Finvizì—ì„œ ìˆ˜ì§‘í•œ 'í—¤ë“œë¼ì¸ ëª©ë¡'ë§Œìœ¼ë¡œ n_lines ì¤„ í•œê¸€ ìš”ì•½ ìƒì„±.
    (ì›ë¬¸ ë§í¬ëŠ” ì½”ë“œì—ì„œ ë³„ë„ë¡œ ì¶œë ¥)
    """
    if not news_items:
        return "ìµœê·¼ 24ì‹œê°„ ë‚´ Finviz ê¸°ì‚¬ ì—†ìŒ"

    if not OPENAI_API_KEY:
        return "OPENAI_API_KEY ëˆ„ë½"

    use = news_items[:max_headlines_for_llm]

    headline_lines = []
    for i, it in enumerate(use, start=1):
        title = (it.get("title") or "").strip()
        if title:
            headline_lines.append(f"{ticker} N{i}: {title}")
    headlines_text = "\n".join(headline_lines).strip()
    if not headlines_text:
        return "ìµœê·¼ 24ì‹œê°„ ë‚´ Finviz ê¸°ì‚¬ ì—†ìŒ"

    prompt = f"""
ì•„ë˜ëŠ” Finvizì—ì„œ ìˆ˜ì§‘í•œ ìµœê·¼ 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ëª©ë¡ì´ë‹¤.

âš ï¸ ë§¤ìš° ì¤‘ìš”:
- ì´ ìš”ì•½ì€ ì˜¤ì§ {company_name}({ticker})ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ë§Œ í¬í•¨í•´ì•¼ í•œë‹¤.
- ë‹¤ë¥¸ ê¸°ì—…(Amazon, Google, Meta ë“±), ì‹œì¥ ì „ì²´, ì •ì¹˜, ê±°ì‹œê²½ì œ ê´€ë ¨ ë‚´ìš©ì€
  í—¤ë“œë¼ì¸ì— í¬í•¨ë˜ì–´ ìˆë”ë¼ë„ ë°˜ë“œì‹œ ì œì™¸í•˜ë¼.
- {company_name}({ticker})ì˜ ì‹¤ì , ì œí’ˆ, ì „ëµ, ì£¼ê°€, ê·œì œ, ì‚¬ì—…ê³¼ ì§ì ‘ ê´€ë ¨ëœ
  ì •ë³´ë§Œ ì‚¬ìš©í•´ ìš”ì•½í•˜ë¼.

ê·œì¹™:
- ì•„ë˜ í—¤ë“œë¼ì¸ ëª©ë¡ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•  ê²ƒ
- {company_name}({ticker})ì™€ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” í—¤ë“œë¼ì¸ì€ ë¬´ì‹œí•  ê²ƒ
- ì¤‘ë³µë˜ëŠ” ì‚¬ê±´ì€ í•˜ë‚˜ë¡œ ë³‘í•©
- ì •í™•íˆ {n_lines}ì¤„ë¡œ í•œê¸€ ìš”ì•½
- ê° ì¤„ì€ í•œ ë¬¸ì¥
- ë²ˆí˜¸/ë¶ˆë¦¿/ì´ëª¨ì§€/ë§ˆí¬ë‹¤ìš´/JSON ì‚¬ìš© ê¸ˆì§€
- ì¶”ì¸¡, í‰ê°€, ì „ë§, ì¼ë°˜ë¡  ê¸ˆì§€

[í—¤ë“œë¼ì¸ ëª©ë¡]
{headlines_text}

ìš”ì•½ë§Œ ì¶œë ¥:
""".strip()

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {OPENAI_API_KEY}"}
    body = {
        "model": OPENAI_MODEL,
        "input": prompt,
        "text": {"format": {"type": "text"}},
    }

    try:
        r = requests.post(OPENAI_URL, headers=headers, json=body, timeout=75)
        if r.status_code != 200:
            return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

        j = r.json()
        txt = (_extract_output_text(j) or "").strip()
        if not txt:
            return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

        # ì¤„ ìˆ˜ ë³´ì •: ë§ìœ¼ë©´ ìë¥´ê³ , ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ(í™˜ê° ë°©ì§€)
        lines = [ln.strip() for ln in txt.splitlines() if ln.strip()]
        if len(lines) > n_lines:
            lines = lines[:n_lines]
        return "\n".join(lines) if lines else "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

    except Exception:
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"


# -------------------------------
# Telegram
# -------------------------------
def send_telegram_msg(message: str) -> bool:
    print("Sending Telegram...")
    if not TELEGRAM_TOKEN or not CHAT_ID:
        print("âŒ Telegram env vars missing")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"

    chunks = [message[i : i + TELEGRAM_CHUNK_SIZE] for i in range(0, len(message), TELEGRAM_CHUNK_SIZE)]
    for idx, chunk in enumerate(chunks, start=1):
        payload = {"chat_id": CHAT_ID, "text": chunk, "disable_web_page_preview": False}
        resp = requests.post(url, data=payload, timeout=20)
        if resp.status_code != 200:
            print(f"âŒ Telegram send failed (part {idx}/{len(chunks)}): {resp.text[:400]}")
            return False

    print("âœ… Telegram sent")
    return True


# -------------------------------
# Report builder
# -------------------------------
def build_report_text(today: str) -> str:
    lines: List[str] = []
    lines.append("ğŸ§  [ë¯¸êµ­ì£¼ì‹ ë°ì¼ë¦¬ ë¸Œë¦¬í•‘ (Finviz / ìµœê·¼ 24ì‹œê°„)]")
    lines.append(f"ğŸ“… {today}")
    lines.append("")

    for c in MAG7:
        t = c["ticker"]
        name = c["name"]
        emoji = c["emoji"]

        n_lines = 20 if t == "TSLA" else 10

        try:
            raw = fetch_finviz_news_with_links_24h(t, max_items=120)
            time.sleep(FINVIZ_SLEEP_SEC)
        except Exception as e:
            lines.append(f"{emoji} {t} â€” {name}")
            lines.append("Finviz ìˆ˜ì§‘ ì‹¤íŒ¨")
            lines.append(f"ì—ëŸ¬: {e}")
            lines.append("\n---\n")
            continue

        deduped = dedupe_news(raw)

        # (ì„ íƒ) ì´ì „ì— ë„£ì—ˆë˜ "í‹°ì»¤/íšŒì‚¬ëª… 1ì°¨ í•„í„°"ë¥¼ ì“°ê³  ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì ìš©
        # deduped_all = filter_headlines_for_ticker(deduped_all, t, name)
        
        # ì‹¤ì  ëª¨ë“œ: ì‹¤ì  í—¤ë“œë¼ì¸ì´ ìˆìœ¼ë©´ ì‹¤ì  ê´€ë ¨ë§Œ ë‚¨ê¹€
        deduped, earnings_mode = filter_earnings_only_if_earnings_day(deduped_all)
        
        summary = summarize_ticker_lines_from_headlines(
            ticker=t,
            company_name=name,
            news_items=deduped,
            n_lines=n_lines,
            max_headlines_for_llm=12,
        )

        price, chg = fetch_finviz_price_change(t)
        time.sleep(FINVIZ_SLEEP_SEC)  # Finviz ìš”ì²­ 1ë²ˆ ë” í•˜ë‹ˆê¹Œ ë”œë ˆì´ ìœ ì§€
        
        suffix = f" ({price}, {chg})" if (price and chg) else ""
        lines.append(f"{emoji} {t} â€” {name}{suffix}")
        lines.append(summary)
"""
        # ì›ë¬¸ ë§í¬: ìƒìœ„ 5ê°œ
        link_items: List[Tuple[str, str]] = []
        for it in deduped[:5]:
            title = (it.get("title") or "").strip()
            url = (it.get("url") or "").strip()
            if title and url:
                link_items.append((title, url))

        if link_items:
            lines.append("")
            lines.append("ì›ë¬¸ ë§í¬")
            for title, url in link_items:
                lines.append(f"- {title}")
                lines.append(f"  {url}")
"""
        lines.append("\n---\n")

    return "\n".join(lines).strip()


# -------------------------------
# Main
# -------------------------------
def main() -> int:
    print("OpenAI key set?", bool(OPENAI_API_KEY))
    print("Token set?", bool(TELEGRAM_TOKEN), "ChatID set?", bool(CHAT_ID))
    print("OpenAI model:", OPENAI_MODEL)

    kst = pytz.timezone("Asia/Seoul")
    today = datetime.datetime.now(kst).strftime("%Y-%m-%d")

    report_text = build_report_text(today)
    ok = send_telegram_msg(report_text)
    return 0 if ok else 1


if __name__ == "__main__":
    sys.exit(main())
