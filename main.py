import requests
import os
import datetime
import pytz
import sys
import json
import time
from typing import Dict, List, Any, Optional

from urllib.parse import quote
from bs4 import BeautifulSoup

# Pillow (PNG ìƒì„±)
from PIL import Image, ImageDraw, ImageFont

# -------------------------------
# Environment Variables
# -------------------------------
OPENAI_API_KEY = (os.environ.get("OPENAI_API_KEY") or "").strip()
TELEGRAM_TOKEN = (os.environ.get("TELEGRAM_TOKEN") or "").strip()
CHAT_ID = (os.environ.get("CHAT_ID") or "").strip()

OPENAI_MODEL = (os.environ.get("OPENAI_MODEL") or "gpt-4o-mini").strip()
OPENAI_URL = "https://api.openai.com/v1/responses"

# âœ… í•„ìš”ì— ë§ê²Œ ì£¼ì„ í•´ì œ/ì¡°ì •
MAG7 = [
    {"name": "Apple", "ticker": "AAPL", "emoji": "ğŸ"},
    {"name": "Microsoft", "ticker": "MSFT", "emoji": "ğŸ’»"},
    {"name": "Amazon", "ticker": "AMZN", "emoji": "ğŸ“¦"},
    {"name": "Alphabet", "ticker": "GOOGL", "emoji": "ğŸ”"},
    {"name": "Meta", "ticker": "META", "emoji": "ğŸ§ "},
    {"name": "NVIDIA", "ticker": "NVDA", "emoji": "ğŸ¤–"},
    {"name": "Tesla", "ticker": "TSLA", "emoji": "ğŸš—"},
]

THEMES = ["AI", "ë¡œë´‡", "ê´‘ê³ ", "í´ë¼ìš°ë“œ", "ë°˜ë„ì²´", "ì „ê¸°ì°¨", "ë¡œë³´íƒì‹œ", "ì‹¤ì ", "ê·œì œ", "ê±°ì‹œ"]
MAX_PER_TICKER = 5
MAX_LINES = 5
KW_PER_THEME = 3
MAX_THEMES_PER_TICKER = 5

# Telegram ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ(4096) ëŒ€ì‘
TELEGRAM_CHUNK_SIZE = 3900

# Finviz ìš”ì²­ ê°„ ë”œë ˆì´(ë´‡ ì°¨ë‹¨ ì™„í™”)
FINVIZ_SLEEP_SEC = 1.0


# -------------------------------
# 1) Fetch Finviz headlines (last 24h only)
# -------------------------------
def fetch_finviz_news(ticker: str, max_items: int = 40) -> List[Dict[str, str]]:
    """
    Finviz quote í˜ì´ì§€ì˜ ë‰´ìŠ¤ í…Œì´ë¸”ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘.
    """
    url = f"https://finviz.com/quote.ashx?t={quote(ticker)}"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (X11; Linux x86_64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0 Safari/537.36"
        )
    }

    r = requests.get(url, headers=headers, timeout=20)
    r.raise_for_status()

    soup = BeautifulSoup(r.text, "lxml")
    table = soup.find("table", class_="news-table")
    if not table:
        return []

    items: List[Dict[str, str]] = []
    rows = table.find_all("tr")
    for row in rows:
        tds = row.find_all("td")
        if len(tds) < 2:
            continue

        dt_txt = tds[0].get_text(" ", strip=True)  # "Today, 6:40 AM" or "Feb-03, 6:40 AM"
        a = tds[1].find("a")
        title = a.get_text(" ", strip=True) if a else tds[1].get_text(" ", strip=True)

        if title:
            items.append({"title": title, "published": dt_txt})

        if len(items) >= max_items:
            break

    return items


def _parse_finviz_datetime_to_kst(dt_txt: str, now_kst: datetime.datetime) -> Optional[datetime.datetime]:
    """
    Finviz í‘œê¸° (Today, 6:40 AM) / (Feb-03, 6:40 AM) ë“±ì„
    US/Eastern ê¸°ì¤€ìœ¼ë¡œ í•´ì„ í›„ KST datetimeìœ¼ë¡œ ë³€í™˜.
    """
    if not dt_txt:
        return None

    et = pytz.timezone("US/Eastern")
    kst = pytz.timezone("Asia/Seoul")

    now_et = now_kst.astimezone(et)
    year = now_et.year

    # Case 1: "Today, 6:40 AM"
    if dt_txt.lower().startswith("today"):
        time_part = dt_txt.split(",", 1)[-1].strip()
        try:
            t = datetime.datetime.strptime(time_part, "%I:%M %p").time()
        except Exception:
            return None
        dt_et = et.localize(datetime.datetime(year, now_et.month, now_et.day, t.hour, t.minute))
        return dt_et.astimezone(kst)

    # Case 2: "Feb-03, 6:40 AM" (ë˜ëŠ” ë³€í˜•)
    norm = dt_txt.replace("-", " ").replace(",", "")
    parts = norm.split()
    if len(parts) >= 4:
        try:
            mon = parts[0]
            day = int(parts[1])
            time_str = " ".join(parts[2:4])  # "6:40 AM"
            t = datetime.datetime.strptime(time_str, "%I:%M %p").time()
            month_num = datetime.datetime.strptime(mon, "%b").month

            dt_et = et.localize(datetime.datetime(year, month_num, day, t.hour, t.minute))

            # ì—°ë§/ì—°ì´ˆ ê²½ê³„ ë³´ì •: ë¯¸ë˜ë¡œ íŠ€ë©´ ì‘ë…„ìœ¼ë¡œ
            if dt_et > now_et + datetime.timedelta(hours=1):
                dt_et = et.localize(datetime.datetime(year - 1, month_num, day, t.hour, t.minute))

            return dt_et.astimezone(kst)
        except Exception:
            return None

    return None


def filter_last_24h(items: List[Dict[str, str]], now_kst: datetime.datetime) -> List[Dict[str, str]]:
    cutoff = now_kst - datetime.timedelta(hours=24)
    out = []
    for it in items:
        pub = (it.get("published") or "").strip()
        dt_kst = _parse_finviz_datetime_to_kst(pub, now_kst)
        if dt_kst and dt_kst >= cutoff:
            out.append(it)
    return out


def get_mag7_news(per_ticker: int = MAX_PER_TICKER) -> Dict[str, Any]:
    print("Fetching news (Finviz, last 24h)...")
    kst = pytz.timezone("Asia/Seoul")
    now_kst = datetime.datetime.now(kst)

    items: Dict[str, List[Dict[str, str]]] = {}

    for c in MAG7:
        ticker = c["ticker"]
        try:
            raw = fetch_finviz_news(ticker, max_items=60)
            recent = filter_last_24h(raw, now_kst=now_kst)
            items[ticker] = recent[:per_ticker]
            print(f"- {ticker}: {len(items[ticker])} headlines (last 24h)")
        except Exception as e:
            print(f"âš ï¸ Finviz fetch failed for {ticker}: {e}")
            items[ticker] = []

        time.sleep(FINVIZ_SLEEP_SEC)

    total = sum(len(v) for v in items.values())
    print(f"Total headlines (last 24h): {total}")
    return {"source": "Finviz (quote page news)", "items": items}


# -------------------------------
# 2) OpenAI JSON summarization (with themes)
# -------------------------------
def _extract_output_text(res_json: dict) -> str:
    text_parts = []
    for item in (res_json.get("output") or []):
        for c in (item.get("content") or []):
            if c.get("type") == "output_text" and isinstance(c.get("text"), str):
                text_parts.append(c["text"])
    return "\n".join(t.strip() for t in text_parts if t and t.strip()).strip()


def _dynamic_schema_block(tickers: List[str], today: str) -> str:
    """
    MAG7 ë¦¬ìŠ¤íŠ¸ê°€ ì¼ë¶€ë§Œ ì¼œì ¸ ìˆì–´ë„ ìŠ¤í‚¤ë§ˆê°€ ì•ˆ ê¹¨ì§€ê²Œ,
    by_tickerë¥¼ 'í˜„ì¬ tickers'ë¡œë§Œ ìš”êµ¬í•˜ë„ë¡ ìŠ¤í‚¤ë§ˆ í…ìŠ¤íŠ¸ ìƒì„±.
    """
    # ì˜ˆì‹œ í‹°ì»¤ í•˜ë‚˜ë¡œ í…œí”Œë¦¿ ë§Œë“¤ê³ , ì‹¤ì œ ìš”êµ¬ëŠ” tickers ì „ì²´ë¡œ
    exemplar = tickers[0] if tickers else "AAPL"
    schema_lines = [
        "{",
        f'  "date_kst": "{today}",',
        '  "universe": "Magnificent 7",',
        '  "overall": {',
        '    "key_takeaways": ["ë¬¸ì¥","ë¬¸ì¥","ë¬¸ì¥","ë¬¸ì¥","ë¬¸ì¥"],',
        '    "market_mood": {',
        '      "label": "ê¸ì •|ì¤‘ë¦½|ë¶€ì •",',
        '      "reason": "í•œ ì¤„ ì´ìœ "',
        "    }",
        "  },",
        '  "by_ticker": {',
    ]

    # tickers ê°ê°ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”êµ¬(ëª¨ë¸ì´ ë¹ ëœ¨ë¦¬ëŠ” ê²ƒ ë°©ì§€)
    for i, t in enumerate(tickers):
        comma = "," if i < len(tickers) - 1 else ""
        schema_lines += [
            f'    "{t}": {{',
            '      "themes": [',
            '        {"theme":"AI","keywords":["í‚¤ì›Œë“œ","í‚¤ì›Œë“œ","í‚¤ì›Œë“œ"]}',
            "      ],",
            f'      "headline_translations": ["í•œê¸€ ë²ˆì—­"(ìµœëŒ€ {MAX_PER_TICKER}ê°œ)],',
            '      "summary": {',
            f'        "bullish": ["í˜¸ì¬"(ìµœëŒ€ {MAX_LINES}ê°œ)],',
            f'        "bearish": ["ì•…ì¬"(ìµœëŒ€ {MAX_LINES}ê°œ)],',
            f'        "watchlist": ["ê´€ì „ í¬ì¸íŠ¸"(ìµœëŒ€ {MAX_LINES}ê°œ)]',
            "      },",
            '      "mood": "ê¸ì •|ì¤‘ë¦½|ë¶€ì •"',
            f"    }}{comma}",
        ]

    schema_lines += [
        "  }",
        "}",
    ]
    return "\n".join(schema_lines)


def summarize_mag7_to_json(news_blob: Dict[str, Any], today: str) -> Optional[Dict[str, Any]]:
    print("Analyzing with ChatGPT (OpenAI Responses API) - JSON output...")

    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY missing")
        return None

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {OPENAI_API_KEY}"}

    tickers = [c["ticker"] for c in MAG7]

    compact_lines = []
    for c in MAG7:
        t = c["ticker"]
        name = c["name"]
        headlines = news_blob["items"].get(t, [])
        for i, h in enumerate(headlines, start=1):
            title = h.get("title", "")
            published = h.get("published", "")
            if published:
                compact_lines.append(f"{t} ({name}) H{i}: {title} [{published}]")
            else:
                compact_lines.append(f"{t} ({name}) H{i}: {title}")
    headlines_text = "\n".join(compact_lines).strip()

    theme_list = ", ".join(THEMES)
    schema_block = _dynamic_schema_block(tickers=tickers, today=today)

    prompt = f"""
ë„ˆëŠ” ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ë‰´ìŠ¤ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼.
ì•„ë˜ëŠ” ì˜¤ëŠ˜(ìµœê·¼ 24ì‹œê°„ ì´ë‚´) ìˆ˜ì§‘ëœ í—¤ë“œë¼ì¸ì´ë‹¤.

ë°˜ë“œì‹œ 'ìœ íš¨í•œ JSONë§Œ' ì¶œë ¥í•´. (ë§ˆí¬ë‹¤ìš´/ì½”ë“œë¸”ë¡/ì„¤ëª… ë¬¸ì¥ ê¸ˆì§€)

í…Œë§ˆëŠ” ë°˜ë“œì‹œ ì•„ë˜ ëª©ë¡ ì¤‘ì—ì„œë§Œ ì„ íƒí•´:
[{theme_list}]

ìŠ¤í‚¤ë§ˆ(ë°˜ë“œì‹œ ì¤€ìˆ˜):
{schema_block}

ê·œì¹™:
- overall.key_takeawaysëŠ” ì •í™•íˆ 5ê°œ.
- themesëŠ” í‹°ì»¤ë‹¹ 1~{MAX_THEMES_PER_TICKER}ê°œ(ê°€ëŠ¥í•˜ë©´ 2~4ê°œ).
- ê° theme.keywordsëŠ” ì •í™•íˆ 3ê°œ(ì§§ê²Œ, ëª…ì‚¬í˜•, ì¤‘ë³µ í”¼í•˜ê¸°).
- headline_translations ìµœëŒ€ {MAX_PER_TICKER}ê°œ.
- bullish/bearish/watchlist ê° ìµœëŒ€ {MAX_LINES}ê°œ(ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ê°€ëŠ¥).
- ì „ë¶€ í•œêµ­ì–´(ì˜ì–´/URL ê¸ˆì§€), í•œ ì¤„ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ.

[í—¤ë“œë¼ì¸ ë°ì´í„°]
{headlines_text}
""".strip()

    # Responses API: ê°€ëŠ¥í•˜ë©´ json_object ê°•ì œ(ëª¨ë¸/ê³„ì •ì— ë”°ë¼ ë¯¸ì§€ì›ì¼ ìˆ˜ ìˆì–´ fallback í¬í•¨)
    body = {
        "model": OPENAI_MODEL,
        "input": prompt,
        "response_format": {"type": "json_object"},
    }

    try:
        r = requests.post(OPENAI_URL, headers=headers, json=body, timeout=75)
        if r.status_code != 200:
            # json_object ë¯¸ì§€ì› ë“±ì¼ ìˆ˜ ìˆì–´ fallbackìœ¼ë¡œ ì¬ì‹œë„
            print(f"âš ï¸ OpenAI API non-200 (try fallback) {r.status_code}: {r.text[:300]}")
            body.pop("response_format", None)
            r = requests.post(OPENAI_URL, headers=headers, json=body, timeout=75)
    except requests.RequestException as e:
        print(f"âŒ OpenAI request failed: {e}")
        return None

    if r.status_code != 200:
        print(f"âŒ OpenAI API error {r.status_code}: {r.text[:800]}")
        return None

    try:
        j = r.json()
    except Exception:
        print("âŒ OpenAI response not JSON (outer)")
        return None

    out_text = _extract_output_text(j).strip()
    if not out_text:
        return None

    try:
        return json.loads(out_text)
    except json.JSONDecodeError:
        # tolerate stray text
        start = out_text.find("{")
        end = out_text.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                return json.loads(out_text[start:end + 1])
            except Exception:
                pass
        print("âŒ Failed to parse JSON from model output.")
        return None


# -------------------------------
# 3) Render: JSON -> Card-style text (Telegram/PNG ê³µìš©)
# -------------------------------
def safe_list(x) -> List[Any]:
    return x if isinstance(x, list) else []


def safe_dict(x) -> Dict[str, Any]:
    return x if isinstance(x, dict) else {}


def render_mag7_cards(summary: Dict[str, Any], news_blob: Dict[str, Any]) -> str:
    date_kst = (summary.get("date_kst") or "").strip()
    overall = safe_dict(summary.get("overall"))
    key_takeaways = safe_list(overall.get("key_takeaways"))
    market_mood = safe_dict(overall.get("market_mood"))
    overall_label = (market_mood.get("label") or "").strip()
    overall_reason = (market_mood.get("reason") or "").strip()

    lines: List[str] = []
    lines.append("ğŸ§  [ë¯¸êµ­ì£¼ì‹ ë°ì¼ë¦¬ ë¸Œë¦¬í•‘ (Finviz / ìµœê·¼ 24ì‹œê°„)]")
    if date_kst:
        lines.append(f"ğŸ“… {date_kst}")
    lines.append("")

    lines.append("ğŸ“Œ ì „ì²´ í•µì‹¬ ìš”ì•½")
    for t in key_takeaways[:5]:
        if isinstance(t, str) and t.strip():
            lines.append(f"â€¢ {t.strip()}")
    if overall_label:
        lines.append(f"ğŸ“Š ì „ì²´ ì‹œì¥ ë¶„ìœ„ê¸°: {overall_label}" + (f" â€” {overall_reason}" if overall_reason else ""))
    lines.append("\n---\n")

    by_ticker = safe_dict(summary.get("by_ticker"))

    for c in MAG7:
        t = c["ticker"]
        name = c["name"]
        emoji = c["emoji"]

        data = safe_dict(by_ticker.get(t))
        mood = (data.get("mood") or "ì¤‘ë¦½").strip()

        themes = safe_list(data.get("themes"))
        translations = safe_list(data.get("headline_translations"))
        summary_obj = safe_dict(data.get("summary"))
        bullish = safe_list(summary_obj.get("bullish"))
        bearish = safe_list(summary_obj.get("bearish"))
        watchlist = safe_list(summary_obj.get("watchlist"))

        # fallback: ëª¨ë¸ ë²ˆì—­ì´ ì—†ìœ¼ë©´ ì›ë¬¸ í—¤ë“œë¼ì¸ ëŒ€ì‹  "ìš”ì•½ìš© í•œê¸€ ì œëª©"ì´ ì—†ì–´ì„œ ì˜ë¬¸ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
        # ì—¬ê¸°ì„œëŠ” ì–´ì©” ìˆ˜ ì—†ì´ ì›ë¬¸ ì œëª©ì„ ë…¸ì¶œí•˜ë˜ ë¼ë²¨ì„ "í—¤ë“œë¼ì¸"ìœ¼ë¡œ ì²˜ë¦¬
        fallback_is_english = False
        if not translations:
            orig = news_blob.get("items", {}).get(t, [])
            translations = [h.get("title", "").strip() for h in orig if h.get("title", "").strip()]
            fallback_is_english = True

        lines.append(f"{emoji} {t} â€” {name}")
        lines.append(f"ì‹œì¥ ë¶„ìœ„ê¸°: {mood}")

        # theme tags
        if themes:
            themed_bits = []
            for th in themes[:MAX_THEMES_PER_TICKER]:
                thd = safe_dict(th)
                theme_name = (thd.get("theme") or "").strip()
                kws = [k.strip() for k in safe_list(thd.get("keywords"))[:KW_PER_THEME] if isinstance(k, str) and k.strip()]
                if theme_name and kws:
                    themed_bits.append(f"{theme_name}({', '.join(kws)})")
                elif theme_name:
                    themed_bits.append(theme_name)
            if themed_bits:
                lines.append("ğŸ·ï¸ í…Œë§ˆ: " + " | ".join(themed_bits))

        lines.append("")
        if bullish:
            lines.append("âœ… í˜¸ì¬")
            for x in bullish[:MAX_LINES]:
                if isinstance(x, str) and x.strip():
                    lines.append(f"â€¢ {x.strip()}")
            lines.append("")
        if bearish:
            lines.append("âš ï¸ ì•…ì¬")
            for x in bearish[:MAX_LINES]:
                if isinstance(x, str) and x.strip():
                    lines.append(f"â€¢ {x.strip()}")
            lines.append("")
        if watchlist:
            lines.append("ğŸ‘€ ê´€ì „ í¬ì¸íŠ¸")
            for x in watchlist[:MAX_LINES]:
                if isinstance(x, str) and x.strip():
                    lines.append(f"â€¢ {x.strip()}")
            lines.append("")

        if translations:
            headline_label = "ğŸ“° ì£¼ìš” í—¤ë“œë¼ì¸(ë²ˆì—­)" if not fallback_is_english else "ğŸ“° ì£¼ìš” í—¤ë“œë¼ì¸"
            lines.append(headline_label)
            for h in translations[:MAX_PER_TICKER]:
                if isinstance(h, str) and h.strip():
                    lines.append(f"â€¢ {h.strip()}")

        lines.append("\n---\n")

    return "\n".join(lines).strip()


# -------------------------------
# 4) Save PNG
# -------------------------------
def _load_font(size: int) -> ImageFont.ImageFont:
    """
    GitHub Actions(Ubuntu) í¬í•¨, í•œê¸€ í‘œì‹œ ê°€ëŠ¥í•œ í°íŠ¸ë¥¼ ìš°ì„  ë¡œë“œ.
    """
    candidates = [
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        "/usr/share/fonts/opentype/noto/NotoSansCJKkr-Regular.otf",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        "/usr/share/fonts/truetype/noto/NotoSansKR-Regular.otf",
        "/usr/share/fonts/truetype/noto/NotoSansKR-Regular.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/Library/Fonts/AppleGothic.ttf",
        "C:\\Windows\\Fonts\\malgun.ttf",
        "C:\\Windows\\Fonts\\arial.ttf",
    ]

    for p in candidates:
        try:
            if os.path.exists(p):
                return ImageFont.truetype(p, size=size)
        except Exception:
            pass

    return ImageFont.load_default()


def save_report_png(text: str, date_str: str) -> str:
    """
    card í…ìŠ¤íŠ¸ë¥¼ PNGë¡œ ì €ì¥.
    GitHub Actions í™˜ê²½ì—ì„œëŠ” ~/Downloadsê°€ ì—†ì„ ìˆ˜ ìˆì–´ cwdë¡œ ì €ì¥ë¨.
    """
    downloads = os.path.join(os.path.expanduser("~"), "Downloads")
    if not os.path.isdir(downloads):
        downloads = os.getcwd()

    out_path = os.path.join(downloads, f"{date_str}.png")

    W = 1080
    margin = 60
    line_spacing = 10

    font_title = _load_font(42)
    font_body = _load_font(30)

    dummy = Image.new("RGB", (W, 100), "white")
    d = ImageDraw.Draw(dummy)

    def wrap_line(line: str, font: ImageFont.ImageFont, max_width: int) -> List[str]:
        if not line.strip():
            return [""]
        chars = list(line)
        out = []
        cur = ""
        for ch in chars:
            test = cur + ch
            try:
                ok = d.textlength(test, font=font) <= max_width
            except Exception:
                # ì¼ë¶€ í™˜ê²½ì—ì„œ ì´ëª¨ì§€/í°íŠ¸ ë¬¸ì œ ì‹œ ëŒ€ëµì ì¸ fallback
                ok = len(test) * (font.size * 0.6) <= max_width
            if ok:
                cur = test
            else:
                out.append(cur)
                cur = ch
        out.append(cur)
        return out

    max_text_width = W - 2 * margin
    lines_raw = text.splitlines()

    wrapped: List[tuple] = []
    for i, ln in enumerate(lines_raw):
        if i == 0:
            for wln in wrap_line(ln, font_title, max_text_width):
                wrapped.append(("title", wln))
        else:
            for wln in wrap_line(ln, font_body, max_text_width):
                wrapped.append(("body", wln))

    y = margin
    for kind, ln in wrapped:
        font = font_title if kind == "title" else font_body
        bbox = d.textbbox((0, 0), ln, font=font)
        h = (bbox[3] - bbox[1]) if bbox else (50 if kind == "title" else 36)
        y += h + line_spacing
    H = y + margin

    img = Image.new("RGB", (W, H), (255, 255, 255))
    draw = ImageDraw.Draw(img)

    y = margin
    for kind, ln in wrapped:
        font = font_title if kind == "title" else font_body
        draw.text((margin, y), ln, font=font, fill=(0, 0, 0))
        bbox = draw.textbbox((margin, y), ln, font=font)
        h = (bbox[3] - bbox[1]) if bbox else (50 if kind == "title" else 36)
        y += h + line_spacing

    img.save(out_path, "PNG")
    return out_path


# -------------------------------
# 5) Telegram (chunked)
# -------------------------------
def send_telegram_msg(message: str) -> bool:
    print("Sending Telegram...")
    if not TELEGRAM_TOKEN or not CHAT_ID:
        print("âŒ Telegram env vars missing")
        return False

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"

    chunks = [message[i:i + TELEGRAM_CHUNK_SIZE] for i in range(0, len(message), TELEGRAM_CHUNK_SIZE)]
    for idx, chunk in enumerate(chunks, start=1):
        payload = {"chat_id": CHAT_ID, "text": chunk, "disable_web_page_preview": True}
        resp = requests.post(url, data=payload, timeout=20)
        if resp.status_code != 200:
            print(f"âŒ Telegram send failed (part {idx}/{len(chunks)}): {resp.text}")
            return False

    print("âœ… Telegram sent")
    return True


# -------------------------------
# 6) Main
# -------------------------------
def main():
    print("OpenAI key set?", bool(OPENAI_API_KEY))
    print("Token set?", bool(TELEGRAM_TOKEN), "ChatID set?", bool(CHAT_ID))
    print("OpenAI model:", OPENAI_MODEL)

    kst = pytz.timezone("Asia/Seoul")
    today = datetime.datetime.now(kst).strftime("%Y-%m-%d")

    news_blob = get_mag7_news(per_ticker=MAX_PER_TICKER)
    summary_json = summarize_mag7_to_json(news_blob, today=today)

    if summary_json is None:
        # fallback summary
        summary_json = {
            "date_kst": today,
            "universe": "Magnificent 7",
            "overall": {
                "key_takeaways": [],
                "market_mood": {"label": "ì¤‘ë¦½", "reason": "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"}
            },
            "by_ticker": {
                t["ticker"]: {
                    "themes": [],
                    "headline_translations": [],
                    "summary": {"bullish": [], "bearish": [], "watchlist": []},
                    "mood": "ì¤‘ë¦½"
                } for t in MAG7
            }
        }

    # 1) ì¹´ë“œ í…ìŠ¤íŠ¸ ìƒì„±
    report_text = render_mag7_cards(summary_json, news_blob)

    # 2) Telegram ì „ì†¡
    ok_tg = send_telegram_msg(report_text)

    # 3) PNG ì €ì¥
    try:
        out_path = save_report_png(report_text, today)
        print(f"âœ… Saved PNG: {out_path}")
    except Exception as e:
        print(f"âŒ PNG save failed: {e}")
        out_path = ""

    return 0 if ok_tg else 1


if __name__ == "__main__":
    sys.exit(main())
